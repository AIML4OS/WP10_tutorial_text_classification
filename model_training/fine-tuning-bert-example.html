<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.34">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>fine-tuning-bert-example – Educational resource template for Python</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../5_RAG/rag_classification.html" rel="next">
<link href="../data_preprocessing/data_augmentation.html" rel="prev">
<link href="../resources/profile/main3.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-c8ad9e5dbd60b7b70b38521ab19b7da4.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-d68be38d83eca2bb035acf846ffba811.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../model_training/fine-tuning-bert-example.html">Transformers for text classification</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
      <a href="../index.html" class="sidebar-logo-link">
      <img src="../resources/profile/main3.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data_preprocessing/data_augmentation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data augmentation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../model_training/fine-tuning-bert-example.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Transformers for text classification</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../5_RAG/rag_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">RAG Classification</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#bert-base-multilingual-fine-tuning" id="toc-bert-base-multilingual-fine-tuning" class="nav-link active" data-scroll-target="#bert-base-multilingual-fine-tuning">BERT base multilingual Fine-Tuning</a></li>
  <li><a href="#fine-tuning-a-transformers-model-guide" id="toc-fine-tuning-a-transformers-model-guide" class="nav-link" data-scroll-target="#fine-tuning-a-transformers-model-guide">Fine-Tuning a Transformers Model Guide</a>
  <ul class="collapse">
  <li><a href="#dependancy-management" id="toc-dependancy-management" class="nav-link" data-scroll-target="#dependancy-management">Dependancy management</a></li>
  <li><a href="#configuration-variables-and-parameters" id="toc-configuration-variables-and-parameters" class="nav-link" data-scroll-target="#configuration-variables-and-parameters">Configuration variables and parameters</a>
  <ul class="collapse">
  <li><a href="#model-settings" id="toc-model-settings" class="nav-link" data-scroll-target="#model-settings"><strong>Model Settings</strong></a></li>
  <li><a href="#output-settings" id="toc-output-settings" class="nav-link" data-scroll-target="#output-settings"><strong>Output Settings</strong></a></li>
  <li><a href="#training-hyperparameters" id="toc-training-hyperparameters" class="nav-link" data-scroll-target="#training-hyperparameters"><strong>Training Hyperparameters</strong></a></li>
  <li><a href="#evaluation-logging" id="toc-evaluation-logging" class="nav-link" data-scroll-target="#evaluation-logging"><strong>Evaluation &amp; Logging</strong></a></li>
  <li><a href="#precision-model-loading" id="toc-precision-model-loading" class="nav-link" data-scroll-target="#precision-model-loading"><strong>Precision &amp; Model Loading</strong></a></li>
  </ul></li>
  </ul></li>
  <li><a href="#load-a-csv-dataset-and-convert-it-into-the-hugging-face-datasets-format" id="toc-load-a-csv-dataset-and-convert-it-into-the-hugging-face-datasets-format" class="nav-link" data-scroll-target="#load-a-csv-dataset-and-convert-it-into-the-hugging-face-datasets-format">1. Load a CSV dataset and convert it into the Hugging Face Datasets format</a>
  <ul class="collapse">
  <li><a href="#convert-dataframe-to-hugging-face-dataset" id="toc-convert-dataframe-to-hugging-face-dataset" class="nav-link" data-scroll-target="#convert-dataframe-to-hugging-face-dataset">Convert DataFrame to Hugging Face Dataset</a></li>
  <li><a href="#convert-string-labels-to-integers-using-labelencoder" id="toc-convert-string-labels-to-integers-using-labelencoder" class="nav-link" data-scroll-target="#convert-string-labels-to-integers-using-labelencoder">Convert string labels to integers using LabelEncoder</a></li>
  <li><a href="#keep-id2label-and-label2id" id="toc-keep-id2label-and-label2id" class="nav-link" data-scroll-target="#keep-id2label-and-label2id">Keep <code>id2label</code> and <code>label2id</code></a></li>
  <li><a href="#use-classlabel-and-stratified-split" id="toc-use-classlabel-and-stratified-split" class="nav-link" data-scroll-target="#use-classlabel-and-stratified-split">Use ClassLabel and Stratified Split</a></li>
  </ul></li>
  <li><a href="#load-a-pretrained-model-and-tokenizer-from-the-hugging-face-hub" id="toc-load-a-pretrained-model-and-tokenizer-from-the-hugging-face-hub" class="nav-link" data-scroll-target="#load-a-pretrained-model-and-tokenizer-from-the-hugging-face-hub">2. Load a pretrained model and tokenizer from the Hugging Face Hub</a>
  <ul class="collapse">
  <li><a href="#loading-a-pretrained-model" id="toc-loading-a-pretrained-model" class="nav-link" data-scroll-target="#loading-a-pretrained-model"><strong>Loading a Pretrained Model</strong></a></li>
  <li><a href="#loading-the-tokenizer" id="toc-loading-the-tokenizer" class="nav-link" data-scroll-target="#loading-the-tokenizer"><strong>Loading the Tokenizer</strong></a></li>
  <li><a href="#remarks" id="toc-remarks" class="nav-link" data-scroll-target="#remarks"><strong>Remarks</strong></a></li>
  </ul></li>
  <li><a href="#tokenize-text-using-the-models-tokenizer" id="toc-tokenize-text-using-the-models-tokenizer" class="nav-link" data-scroll-target="#tokenize-text-using-the-models-tokenizer">3. Tokenize text using the model’s tokenizer</a></li>
  <li><a href="#fine-tune-the-model-with-the-transformers-trainer-api" id="toc-fine-tune-the-model-with-the-transformers-trainer-api" class="nav-link" data-scroll-target="#fine-tune-the-model-with-the-transformers-trainer-api">4. Fine-tune the model with the Transformers Trainer API</a>
  <ul class="collapse">
  <li><a href="#compute_metrics-function" id="toc-compute_metrics-function" class="nav-link" data-scroll-target="#compute_metrics-function">4.1. <code>compute_metrics</code> Function</a>
  <ul class="collapse">
  <li><a href="#inputs" id="toc-inputs" class="nav-link" data-scroll-target="#inputs"><strong>Inputs</strong></a></li>
  <li><a href="#steps" id="toc-steps" class="nav-link" data-scroll-target="#steps"><strong>Steps</strong></a></li>
  </ul></li>
  <li><a href="#datacollatorwithpadding" id="toc-datacollatorwithpadding" class="nav-link" data-scroll-target="#datacollatorwithpadding">4.2. DataCollatorWithPadding</a>
  <ul class="collapse">
  <li><a href="#how-it-works" id="toc-how-it-works" class="nav-link" data-scroll-target="#how-it-works">How it works</a></li>
  <li><a href="#why-use-it" id="toc-why-use-it" class="nav-link" data-scroll-target="#why-use-it">Why use it</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#save-and-load-model-in-local-file-system" id="toc-save-and-load-model-in-local-file-system" class="nav-link" data-scroll-target="#save-and-load-model-in-local-file-system">5. Save and load model in local file system</a></li>
  <li><a href="#evaluate-the-model-and-run-predictions-on-test-dataset-with-transformers-pipeline" id="toc-evaluate-the-model-and-run-predictions-on-test-dataset-with-transformers-pipeline" class="nav-link" data-scroll-target="#evaluate-the-model-and-run-predictions-on-test-dataset-with-transformers-pipeline">6. Evaluate the model and run predictions on test dataset with transformers pipeline</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.dev/yulinhuang/WP10_tutorial_text_classification/blob/main/model_training/fine-tuning-bert-example.ipynb" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/yulinhuang/WP10_tutorial_text_classification/blob/main/model_training/fine-tuning-bert-example.ipynb" class="toc-action"><i class="bi empty"></i>View source</a></li><li><a href="https://github.com/yulinhuang/WP10_tutorial_text_classification/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<p><a href="https://datalab.sspcloud.fr/launcher/ide/jupyter-python-gpu?name=Fine-tuning-tutorial-gpu&amp;version=2.3.18&amp;s3=region-79669f20&amp;init.personalInit=«https%3A%2F%2Fraw.githubusercontent.com%2Fyulinhuang%2FWP10_tutorial_text_classification%2Frefs%2Fheads%2Fmerge-template%2Fsspcloud%2Finit-trainees-fine-tune.sh»&amp;git.enabled=false&amp;autoLaunch=true" target="_blank" rel="noopener" data-original-href="https://datalab.sspcloud.fr/launcher/ide/jupyter-python-gpu?name=Fine-tuning-tutorial-gpu&amp;version=2.3.18&amp;s3=region-79669f20&amp;init.personalInit=«https%3A%2F%2Fraw.githubusercontent.com%2Fyulinhuang%2FWP10_tutorial_text_classification%2Frefs%2Fheads%2Fmerge-template%2Fsspcloud%2Finit-trainees-fine-tune.sh»&amp;git.enabled=false&amp;autoLaunch=true"><img src="https://custom-icon-badges.demolab.com/badge/SSP%20Cloud-Launch_with_JupyterLab-blue?logo=jupyter&amp;logoColor=white" alt="Onyxia"></a></p>
<section id="bert-base-multilingual-fine-tuning" class="level1">
<h1>BERT base multilingual Fine-Tuning</h1>
<p>This notebook explores fine-tuning BERT base for text classification.</p>
</section>
<section id="fine-tuning-a-transformers-model-guide" class="level1">
<h1>Fine-Tuning a Transformers Model Guide</h1>
<p>In this tutorial, we’ll build a text classifier by fine-tuning a pretrained BERT model from Hugging Face’s Transformers library. We’ll start from a very practical point: you already have a labeled dataset stored in a CSV file, where each row contains a piece of text and its corresponding label. By the end, you’ll know how to:</p>
<ol type="1">
<li><p>Load a CSV dataset and convert it into the Hugging Face Datasets format</p></li>
<li><p>Load a pretrained model and tokenizer from the Hugging Face Hub</p></li>
<li><p>Tokenize text using the model’s tokenizer</p></li>
<li><p>Fine-tune the model with the Transformers Trainer API</p></li>
<li><p>Save and load model in local file system</p></li>
<li><p>Evaluate the model and run predictions on test dataset with transformers pipeline</p></li>
</ol>
<section id="dependancy-management" class="level2">
<h2 class="anchored" data-anchor-id="dependancy-management">Dependancy management</h2>
<p>Here we import all dependancies that we will need to use</p>
<div id="247af92c-1254-40be-8fb6-848450d821f5" class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> (</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    AutoTokenizer,</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    AutoModelForSequenceClassification,</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    Trainer,</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    TrainingArguments,</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    DataCollatorWithPadding,</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    pipeline,</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    set_seed</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> Dataset, ClassLabel, DatasetDict</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, f1_score, precision_score, recall_score, top_k_accuracy_score</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="configuration-variables-and-parameters" class="level2">
<h2 class="anchored" data-anchor-id="configuration-variables-and-parameters">Configuration variables and parameters</h2>
<p>Here, we can set some parameters with arbitrary value for importing and training.</p>
<hr>
<section id="model-settings" class="level3">
<h3 class="anchored" data-anchor-id="model-settings"><strong>Model Settings</strong></h3>
<table class="caption-top table">
<colgroup>
<col style="width: 24%">
<col style="width: 13%">
<col style="width: 33%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Type</th>
<th>Example Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>model_id</code></td>
<td><code>str</code></td>
<td><code>'bert-base-multilingual-uncased'</code></td>
<td>The Hugging Face model ID to load from the hub. Here, a multilingual BERT model is used for supporting multiple languages.</td>
</tr>
<tr class="even">
<td><code>max_seq_len</code></td>
<td><code>int</code></td>
<td><code>256</code></td>
<td>The maximum number of tokens in an input sequence. Longer sequences will be truncated.</td>
</tr>
</tbody>
</table>
<hr>
</section>
<section id="output-settings" class="level3">
<h3 class="anchored" data-anchor-id="output-settings"><strong>Output Settings</strong></h3>
<table class="caption-top table">
<colgroup>
<col style="width: 24%">
<col style="width: 13%">
<col style="width: 33%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Type</th>
<th>Example Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>output_dir</code></td>
<td><code>str</code></td>
<td><code>'saved_models/bert-base-multilingual-uncased'</code></td>
<td>Directory where the trained model, tokenizer, and training logs will be saved.</td>
</tr>
</tbody>
</table>
<hr>
</section>
<section id="training-hyperparameters" class="level3">
<h3 class="anchored" data-anchor-id="training-hyperparameters"><strong>Training Hyperparameters</strong></h3>
<table class="caption-top table">
<colgroup>
<col style="width: 24%">
<col style="width: 13%">
<col style="width: 33%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Type</th>
<th>Example Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>epochs</code></td>
<td><code>int</code></td>
<td><code>4</code></td>
<td>Number of training epochs. One epoch means going through the full dataset once.</td>
</tr>
<tr class="even">
<td><code>learn_rate</code></td>
<td><code>float</code></td>
<td><code>5e-5</code></td>
<td>Initial learning rate for the optimizer (AdamW by default).</td>
</tr>
<tr class="odd">
<td><code>scheduler</code></td>
<td><code>str</code></td>
<td><code>'linear'</code></td>
<td>Learning rate scheduler type. <code>'linear'</code> gradually decreases the LR after a warmup period.</td>
</tr>
<tr class="even">
<td><code>train_bs</code></td>
<td><code>int</code></td>
<td><code>16</code></td>
<td>Batch size for training steps.</td>
</tr>
<tr class="odd">
<td><code>eval_bs</code></td>
<td><code>int</code></td>
<td><code>32</code></td>
<td>Batch size for evaluation steps.</td>
</tr>
<tr class="even">
<td><code>ga_steps</code></td>
<td><code>int</code></td>
<td><code>2</code></td>
<td>Gradient accumulation steps. Allows you to simulate a larger batch size without increasing GPU memory usage.</td>
</tr>
<tr class="odd">
<td><code>decay</code></td>
<td><code>float</code></td>
<td><code>0.01</code></td>
<td>Weight decay to prevent overfitting by penalizing large weights.</td>
</tr>
<tr class="even">
<td><code>warmup</code></td>
<td><code>float</code></td>
<td><code>0.1</code></td>
<td>Fraction of total training steps used for learning rate warmup.</td>
</tr>
</tbody>
</table>
<hr>
</section>
<section id="evaluation-logging" class="level3">
<h3 class="anchored" data-anchor-id="evaluation-logging"><strong>Evaluation &amp; Logging</strong></h3>
<table class="caption-top table">
<colgroup>
<col style="width: 24%">
<col style="width: 13%">
<col style="width: 33%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Type</th>
<th>Example Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>eval_strategy</code></td>
<td><code>str</code></td>
<td><code>'epoch'</code></td>
<td>When to run evaluation. <code>'epoch'</code> means after each epoch.</td>
</tr>
<tr class="even">
<td><code>logging_strategy</code></td>
<td><code>str</code></td>
<td><code>'epoch'</code></td>
<td>When to log metrics. <code>'epoch'</code> means at the end of each epoch.</td>
</tr>
<tr class="odd">
<td><code>save_strategy</code></td>
<td><code>str</code></td>
<td><code>'no'</code></td>
<td>When to save model checkpoints. <code>'no'</code> means only final save at the end of training.</td>
</tr>
<tr class="even">
<td><code>log_level</code></td>
<td><code>str</code></td>
<td><code>'warning'</code></td>
<td>Logging verbosity. Options include <code>'debug'</code>, <code>'info'</code>, <code>'warning'</code>, <code>'error'</code>.</td>
</tr>
<tr class="odd">
<td><code>report_to</code></td>
<td><code>list</code></td>
<td><code>[]</code></td>
<td>List of reporting integrations (<code>"wandb"</code>, <code>"tensorboard"</code>, etc.). Empty means no external reporting.</td>
</tr>
<tr class="even">
<td><code># log_steps</code></td>
<td><code>int</code></td>
<td><em>(commented out)</em></td>
<td>If enabled, logs training metrics every <code>log_steps</code> steps.</td>
</tr>
</tbody>
</table>
<hr>
</section>
<section id="precision-model-loading" class="level3">
<h3 class="anchored" data-anchor-id="precision-model-loading"><strong>Precision &amp; Model Loading</strong></h3>
<table class="caption-top table">
<colgroup>
<col style="width: 24%">
<col style="width: 13%">
<col style="width: 33%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Type</th>
<th>Example Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>fp16</code></td>
<td><code>bool</code></td>
<td><code>False</code></td>
<td>Whether to use 16-bit floating-point precision (mixed precision) for faster and memory-efficient training.</td>
</tr>
<tr class="even">
<td><code>load_best</code></td>
<td><code>bool</code></td>
<td><code>False</code></td>
<td>Whether to load the best checkpoint after training based on evaluation metrics.</td>
</tr>
</tbody>
</table>
<hr>
<section id="notes" class="level4">
<h4 class="anchored" data-anchor-id="notes"><strong>Notes</strong></h4>
<ul>
<li><strong>Gradient Accumulation (<code>ga_steps</code>)</strong>: With <code>train_bs = 16</code> and <code>ga_steps = 2</code>, the <em>effective batch size</em> is <code>16 * 2 = 32</code>.</li>
<li><strong>Warmup (<code>warmup</code>)</strong>: If you have 1000 total steps, <code>warmup=0.1</code> means the first 100 steps will gradually ramp up the learning rate.</li>
<li><strong>Mixed Precision (<code>fp16</code>)</strong>: Useful on GPUs with Tensor Cores (e.g., NVIDIA RTX series) to speed up training and reduce memory usage.</li>
</ul>
<hr>
<div id="bae37359-4749-441e-90c6-945d6ef32247" class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>model_id        : <span class="bu">str</span>   <span class="op">=</span> <span class="ss">f'bert-base-multilingual-uncased'</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>max_seq_len     : <span class="bu">int</span>   <span class="op">=</span> <span class="dv">256</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>output_dir      : <span class="bu">str</span>   <span class="op">=</span> <span class="ss">f'saved_models/</span><span class="sc">{</span>model_id<span class="sc">}</span><span class="ss">'</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>epochs          : <span class="bu">int</span>   <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>learn_rate      : <span class="bu">float</span> <span class="op">=</span> <span class="fl">5e-5</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>scheduler       : <span class="bu">str</span>   <span class="op">=</span> <span class="st">'linear'</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>train_bs        : <span class="bu">int</span>   <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>eval_bs         : <span class="bu">int</span>   <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>ga_steps        : <span class="bu">int</span>   <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>decay           : <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>warmup          : <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>eval_strategy   : <span class="bu">str</span>   <span class="op">=</span> <span class="st">'epoch'</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>logging_strategy: <span class="bu">str</span>   <span class="op">=</span> <span class="st">'epoch'</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>save_strategy   : <span class="bu">str</span>   <span class="op">=</span> <span class="st">'no'</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>fp16            : <span class="bu">bool</span>  <span class="op">=</span> <span class="va">False</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>load_best       : <span class="bu">bool</span>  <span class="op">=</span> <span class="va">False</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>report_to       : <span class="bu">list</span>  <span class="op">=</span> []</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>log_level       : <span class="bu">str</span>   <span class="op">=</span> <span class="st">'warning'</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>SEED            : <span class="bu">int</span>   <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">'cpu'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="3392175d-afcd-4a35-bf93-3a2161ba485f" class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>set_seed(SEED)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
</section>
</section>
<section id="load-a-csv-dataset-and-convert-it-into-the-hugging-face-datasets-format" class="level1">
<h1>1. Load a CSV dataset and convert it into the Hugging Face Datasets format</h1>
<section id="convert-dataframe-to-hugging-face-dataset" class="level2">
<h2 class="anchored" data-anchor-id="convert-dataframe-to-hugging-face-dataset">Convert DataFrame to Hugging Face Dataset</h2>
<p>Transforming a Pandas DataFrame into a Hugging Face <code>Dataset</code> makes it directly compatible with the <code>Trainer</code> API. This enables efficient tokenization, easy dataset splitting, and optimized batch processing.</p>
</section>
<section id="convert-string-labels-to-integers-using-labelencoder" class="level2">
<h2 class="anchored" data-anchor-id="convert-string-labels-to-integers-using-labelencoder">Convert string labels to integers using LabelEncoder</h2>
<p>Machine learning models require labels as numeric IDs instead of text. Encoding labels ensures they are in a format the model can use.</p>
</section>
<section id="keep-id2label-and-label2id" class="level2">
<h2 class="anchored" data-anchor-id="keep-id2label-and-label2id">Keep <code>id2label</code> and <code>label2id</code></h2>
<p>These mappings connect numeric label IDs with their human-readable names. <code>id2label</code> converts predictions into class names for interpretability, while <code>label2id</code> ensures correct label-to-ID conversion during training. Storing them in the model configuration makes inference outputs understandable.</p>
</section>
<section id="use-classlabel-and-stratified-split" class="level2">
<h2 class="anchored" data-anchor-id="use-classlabel-and-stratified-split">Use ClassLabel and Stratified Split</h2>
<p><code>ClassLabel</code> preserves both the numeric ID and the original label name inside the dataset, improving readability and compatibility. A stratified split ensures that the proportion of each class is maintained between the training and validation sets, leading to more reliable evaluation results.</p>
<div id="49301db0-046f-42af-b2d6-426f33f206ab" class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"data/raw/nace_train.csv"</span>, <span class="co"># </span><span class="al">TODO</span><span class="co">: change to augmented dataset</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    index_col<span class="op">=</span><span class="dv">0</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="44bb4c91-a93d-476b-9517-f1884d3360f3" class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> DatasetDict({</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'train'</span>: Dataset.from_pandas(df)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="b3891988-c059-42a1-957e-277b50f26a15" class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'train'</span>][<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="a6282b25-1e24-474a-9978-8aae7ed4ba15" class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>label_encoder <span class="op">=</span> LabelEncoder()</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>label_encoder.fit(data[<span class="st">'train'</span>][<span class="st">'label'</span>])</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate mappings</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>id2label <span class="op">=</span> {i: <span class="bu">str</span>(label) <span class="cf">for</span> i, label <span class="kw">in</span> <span class="bu">enumerate</span>(label_encoder.classes_)}</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>label2id <span class="op">=</span> {label: i <span class="cf">for</span> i, label <span class="kw">in</span> id2label.items()}</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>class_label <span class="op">=</span> ClassLabel(names<span class="op">=</span>label_encoder.classes_.tolist())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="a23e3d45-0201-4b6d-b797-a93d2f9015cc" class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.<span class="bu">map</span>(<span class="kw">lambda</span> x: {<span class="st">'label'</span>: label_encoder.transform(x[<span class="st">'label'</span>])}, batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Map your dataset to use the ClassLabel feature for stratification</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.cast_column(<span class="st">'label'</span>, class_label)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="0e812b5b-48e0-4ad2-a2d2-f45fe91f973c" class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data[<span class="st">'train'</span>].train_test_split(test_size<span class="op">=</span><span class="fl">0.05</span>, seed<span class="op">=</span>SEED, stratify_by_column<span class="op">=</span><span class="st">"label"</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>data[<span class="st">"validation"</span>] <span class="op">=</span> data.pop(<span class="st">"test"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="load-a-pretrained-model-and-tokenizer-from-the-hugging-face-hub" class="level1">
<h1>2. Load a pretrained model and tokenizer from the Hugging Face Hub</h1>
<p>Load the model and tokenizer from huggingface. If the model is gated or private, you need to set an environment variable called “HF_TOKEN” that contans your huggingface token.</p>
<section id="loading-a-pretrained-model" class="level2">
<h2 class="anchored" data-anchor-id="loading-a-pretrained-model"><strong>Loading a Pretrained Model</strong></h2>
<p><code>AutoModelForSequenceClassification.from_pretrained(...)</code> downloads (or loads from cache) a transformer model designed for text classification.</p>
<ul>
<li><strong><code>model_id</code></strong>: Identifies the model on the Hugging Face Hub (e.g., <code>"bert-base-multilingual-uncased"</code>).<br>
</li>
<li><strong><code>num_labels</code></strong>: Sets the number of output classes for the classification task.<br>
</li>
<li><strong><code>id2label</code></strong> / <strong><code>label2id</code></strong>: Provide mappings between numeric label IDs and human-readable labels, stored in the model configuration so predictions can be interpreted later.<br>
</li>
<li><strong><code>.to(device)</code></strong>: Moves the model’s weights to the chosen hardware (CPU or GPU) for faster computation.</li>
</ul>
<p><strong>Interaction with Hugging Face Hub</strong><br>
When called for the first time with a given <code>model_id</code>, Hugging Face will: 1. <strong>Check the local cache</strong> (default: <code>~/.cache/huggingface/transformers</code> or path from <code>HF_HOME</code> env variable). 2. If not found locally, <strong>download the model weights and configuration</strong> from the Hugging Face Hub. 3. Save them in the cache for future runs, avoiding repeated downloads.</p>
<hr>
</section>
<section id="loading-the-tokenizer" class="level2">
<h2 class="anchored" data-anchor-id="loading-the-tokenizer"><strong>Loading the Tokenizer</strong></h2>
<p><code>AutoTokenizer.from_pretrained(model_id)</code> loads the tokenizer that matches the chosen model.</p>
<ul>
<li>Retrieves <strong>vocabulary, tokenization rules, and preprocessing steps</strong> needed to convert raw text into token IDs.</li>
<li>Ensures <strong>tokenization is consistent</strong> with the model’s training setup.</li>
<li>Uses the same <strong>cache mechanism</strong> as the model loader: checks local cache, downloads from the Hub if necessary, then stores locally.</li>
</ul>
<hr>
</section>
<section id="remarks" class="level2">
<h2 class="anchored" data-anchor-id="remarks"><strong>Remarks</strong></h2>
<ul>
<li>The <strong>model</strong> and <strong>tokenizer</strong> must match — both are tied to the same <code>model_id</code> to ensure correct input formatting.</li>
<li>Using <code>from_pretrained</code> makes it easy to reuse pretrained weights and tokenizers without manual file handling.</li>
<li>The <strong>cache system</strong> speeds up experimentation, as once a model/tokenizer is downloaded, subsequent runs use the local copy instantly.</li>
</ul>
<div id="fadea798-7cb1-40c8-a94e-72ef7a7c2166" class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    model_id,</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    num_labels<span class="op">=</span><span class="bu">len</span>(id2label), </span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    id2label<span class="op">=</span>id2label, </span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    label2id<span class="op">=</span>label2id,</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>).to(device)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_id)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="tokenize-text-using-the-models-tokenizer" class="level1">
<h1>3. Tokenize text using the model’s tokenizer</h1>
<p>Now we tokenize and pad the data using the pretrained tokenizer.</p>
<div id="54703c8b-2b8b-42cb-b3dc-4d6023b47dd3" class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize(example):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokenizer(example[<span class="st">"text"</span>], padding<span class="op">=</span><span class="va">True</span>, truncation<span class="op">=</span><span class="va">True</span>, max_length<span class="op">=</span>max_seq_len)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>tokenized_data <span class="op">=</span> data.<span class="bu">map</span>(</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    tokenize,</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    batched<span class="op">=</span><span class="va">True</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>     </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="fine-tune-the-model-with-the-transformers-trainer-api" class="level1">
<h1>4. Fine-tune the model with the Transformers Trainer API</h1>
<section id="compute_metrics-function" class="level2">
<h2 class="anchored" data-anchor-id="compute_metrics-function">4.1. <code>compute_metrics</code> Function</h2>
<p>This function calculates multiple evaluation metrics for a classification model.<br>
It is designed to be passed to Hugging Face’s <code>Trainer</code>, which automatically calls it during evaluation.</p>
<hr>
<section id="inputs" class="level3">
<h3 class="anchored" data-anchor-id="inputs"><strong>Inputs</strong></h3>
<ul>
<li><strong><code>eval_pred</code></strong>: A tuple <code>(logits, labels)</code> provided by the Trainer.
<ul>
<li><code>logits</code>: Model outputs before activation (shape: <code>[batch_size, num_classes]</code>).</li>
<li><code>labels</code>: Ground truth class IDs.</li>
</ul></li>
</ul>
<hr>
</section>
<section id="steps" class="level3">
<h3 class="anchored" data-anchor-id="steps"><strong>Steps</strong></h3>
<ol type="1">
<li><p><strong>Unpack predictions and labels</strong></p>
<ul>
<li>Extracts <code>logits</code> and <code>labels</code> from the tuple.</li>
</ul></li>
<li><p><strong>Convert logits to predicted class IDs</strong></p>
<ul>
<li>Uses <code>np.argmax(logits, axis=-1)</code> to choose the class with the highest logit score for each sample.</li>
</ul></li>
<li><p><strong>Determine the number of classes</strong></p>
<ul>
<li>Reads <code>num_classes</code> from <code>logits.shape[1]</code>.</li>
<li>Creates <code>class_labels</code> as a range from <code>0</code> to <code>num_classes - 1</code> to ensure all possible classes are considered in top-k metrics.</li>
</ul></li>
<li><p><strong>Compute metrics</strong></p>
<ul>
<li><strong>Accuracy</strong>: Percentage of correct predictions.</li>
<li><strong>F1 Macro</strong>: F1 score averaged across all classes equally.</li>
<li><strong>Precision Macro</strong>: Average precision across all classes, weighted equally.</li>
<li><strong>Recall Macro</strong>: Average recall across all classes, weighted equally.</li>
<li><strong>Top-1 Accuracy</strong>: Accuracy when considering only the single most likely prediction.</li>
<li><strong>Top-2 Accuracy</strong>: Accuracy when considering the two most likely predictions (checks if the correct class is in the top-2 predicted classes).</li>
</ul>
<p><code>zero_division=0</code> ensures no errors if a class is missing in predictions or labels.</p></li>
<li><p><strong>Return results</strong></p>
<ul>
<li>Returns a dictionary with all computed metrics.<br>
Hugging Face’s <code>Trainer</code> logs these values and uses them for evaluation reports.</li>
</ul></li>
</ol>
<div id="a0ae0d1c-c956-4b44-a377-11e2304b33c5" class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_metrics(eval_pred):</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    logits, labels <span class="op">=</span> eval_pred</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> np.argmax(logits, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    num_classes <span class="op">=</span> logits.shape[<span class="dv">1</span>]</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    class_labels <span class="op">=</span> np.arange(num_classes)  <span class="co"># Ensure all classes are covered</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    accuracy <span class="op">=</span> accuracy_score(labels, predictions)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    f1 <span class="op">=</span> f1_score(labels, predictions, average<span class="op">=</span><span class="st">'macro'</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    precision <span class="op">=</span> precision_score(labels, predictions, average<span class="op">=</span><span class="st">'macro'</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    recall <span class="op">=</span> recall_score(labels, predictions, average<span class="op">=</span><span class="st">'macro'</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    top_1_acc <span class="op">=</span> top_k_accuracy_score(labels, logits, k<span class="op">=</span><span class="dv">1</span>, labels<span class="op">=</span>class_labels)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    top_2_acc <span class="op">=</span> top_k_accuracy_score(labels, logits, k<span class="op">=</span><span class="dv">2</span>, labels<span class="op">=</span>class_labels)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">'accuracy'</span>: accuracy,</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">'f1_macro'</span>: f1,</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">'precision_macro'</span>: precision,</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">'recall_macro'</span>: recall,</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">'top_1_accuracy'</span>: top_1_acc,</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">'top_2_accuracy'</span>: top_2_acc,</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>    }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, we define the training arguments and the trainer class.</p>
</section>
</section>
<section id="datacollatorwithpadding" class="level2">
<h2 class="anchored" data-anchor-id="datacollatorwithpadding">4.2. DataCollatorWithPadding</h2>
<p>The <code>DataCollatorWithPadding</code> is a utility from Hugging Face’s <code>transformers</code> library that handles <strong>dynamic padding</strong> for batches during training and evaluation.</p>
<section id="how-it-works" class="level3">
<h3 class="anchored" data-anchor-id="how-it-works">How it works</h3>
<ul>
<li>Looks at all sequences in the current batch.</li>
<li>Finds the <strong>longest sequence</strong> in that batch.</li>
<li>Pads all other sequences to match that length.</li>
<li>Uses the tokenizer to add the correct padding tokens and attention masks.</li>
</ul>
</section>
<section id="why-use-it" class="level3">
<h3 class="anchored" data-anchor-id="why-use-it">Why use it</h3>
<ul>
<li><strong>Memory efficient</strong> – avoids padding all sequences to a fixed <code>max_seq_len</code>.</li>
<li><strong>Faster training</strong> – smaller average sequence length per batch means fewer computations.</li>
<li><strong>Cleaner code</strong> – no need to pre-pad the dataset manually.</li>
</ul>
<div id="9a0d17b9-215b-49a8-8888-b958a6f6908e" class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>data_collator <span class="op">=</span> DataCollatorWithPadding(tokenizer<span class="op">=</span>tokenizer)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>training_args <span class="op">=</span> TrainingArguments(</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span>output_dir,</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span>epochs,</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span>learn_rate,</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    lr_scheduler_type<span class="op">=</span>scheduler,</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span>train_bs,</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    per_device_eval_batch_size<span class="op">=</span>eval_bs,</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    gradient_accumulation_steps<span class="op">=</span>ga_steps,</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    warmup_ratio<span class="op">=</span>warmup,</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    weight_decay<span class="op">=</span>decay,</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    logging_dir<span class="op">=</span><span class="st">'./logs'</span>,</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># logging_steps=log_steps,</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    logging_strategy<span class="op">=</span>logging_strategy,</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    eval_strategy<span class="op">=</span>eval_strategy,</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    save_strategy<span class="op">=</span>save_strategy,</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    fp16<span class="op">=</span>fp16,</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>    load_best_model_at_end<span class="op">=</span>load_best,</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    report_to<span class="op">=</span>report_to,</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>    log_level<span class="op">=</span>log_level,</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> Trainer(</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>training_args,</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>tokenized_data[<span class="st">'train'</span>],</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>    eval_dataset<span class="op">=</span>tokenized_data[<span class="st">'validation'</span>],</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>    compute_metrics<span class="op">=</span>compute_metrics,</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>    data_collator<span class="op">=</span>data_collator</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Finally, we can start training the model.</p>
<div id="8f52b50c-79cd-4b8a-8dc1-7a50912fd00e" class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>time</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>trainer.train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
</section>
<section id="save-and-load-model-in-local-file-system" class="level1">
<h1>5. Save and load model in local file system</h1>
<div id="7085aff0-77ae-4317-95b8-2f9eb420a677" class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>local_save_path <span class="op">=</span> <span class="st">'models/localsave/bert'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="faf83449-429d-4bd9-aaea-52c769bc9f00" class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Uncomment to save it in local path</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co"># model.save_pretrained(local_save_path)</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># tokenizer.save_pretrained(local_save_path)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="b239a70c-ba15-4f98-b4ea-144913dd2286" class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    local_save_path,</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    local_files_only<span class="op">=</span><span class="va">True</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    local_save_path,</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    local_files_only<span class="op">=</span><span class="va">True</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="evaluate-the-model-and-run-predictions-on-test-dataset-with-transformers-pipeline" class="level1">
<h1>6. Evaluate the model and run predictions on test dataset with transformers pipeline</h1>
<p>Now, we can evaluate the model on our test set.</p>
<div id="620d3765-0a4b-4808-ba6a-2617cb26f4e8" class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> pipeline(</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    task<span class="op">=</span><span class="st">'text-classification'</span>,</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model, </span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    tokenizer<span class="op">=</span>tokenizer, </span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="7174fc13-31d8-4783-aed9-17a04ef987b1" class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>df_test <span class="op">=</span> pd.read_csv(<span class="st">'data/raw/nace_test.csv'</span>, index_col<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="efaa3a09-26a9-446a-bfd4-ab7ce7fb3513" class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>df_test</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="2b523dae-a479-4922-bc63-2bdca8efe4c7" class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> df_test[<span class="st">'label'</span>].tolist()</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> df_test[<span class="st">'text'</span>].tolist()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="9090e2af-e962-47ef-8010-96bc8a223325" class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>time</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> pipe(X_test)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>result_topk <span class="op">=</span> pipe(X_test, top_k<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="88fd305e-d28f-4772-a723-58d27a829ef3" class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> [_[<span class="st">'label'</span>] <span class="cf">for</span> _ <span class="kw">in</span> result]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="1c70ad51-89d4-4358-8a8b-1c0abd93d8bf" class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(y_test, y_pred)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> f1_score(y_test, y_pred, average<span class="op">=</span><span class="st">'macro'</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>precision <span class="op">=</span> precision_score(y_test, y_pred, average<span class="op">=</span><span class="st">'macro'</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>recall <span class="op">=</span> recall_score(y_test, y_pred, average<span class="op">=</span><span class="st">'macro'</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="898974a8-da20-4fef-b2e1-d6532de4b3ff" class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Performance on test set </span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Accuracy score  : </span><span class="sc">{</span>accuracy<span class="sc">:.3f}</span><span class="ss">'</span>)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'F1 score        : </span><span class="sc">{</span>f1<span class="sc">:.3f}</span><span class="ss">'</span>)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'precision score : </span><span class="sc">{</span>precision<span class="sc">:.3f}</span><span class="ss">'</span>)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'recall score    : </span><span class="sc">{</span>recall<span class="sc">:.3f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="f7b0dbd0-7c69-4caf-b2b7-113a0975c31a" class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create probability matrix</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>num_samples <span class="op">=</span> <span class="bu">len</span>(result_topk)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>num_classes <span class="op">=</span> <span class="bu">len</span>(label2id)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>y_pred_proba <span class="op">=</span> np.zeros((num_samples, num_classes))</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, sample <span class="kw">in</span> <span class="bu">enumerate</span>(result_topk):</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> pred <span class="kw">in</span> sample:</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>        class_idx <span class="op">=</span> label2id[pred[<span class="st">'label'</span>]]</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>        y_pred_proba[i][class_idx] <span class="op">=</span> pred[<span class="st">'score'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="bc254999-0d58-4151-a25a-017a7af0bc50" class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>top1 <span class="op">=</span> top_k_accuracy_score(y_test, y_pred_proba, k<span class="op">=</span><span class="dv">1</span>, labels<span class="op">=</span><span class="bu">list</span>(label2id.keys()))</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>top2 <span class="op">=</span> top_k_accuracy_score(y_test, y_pred_proba, k<span class="op">=</span><span class="dv">2</span>, labels<span class="op">=</span><span class="bu">list</span>(label2id.keys()))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="81d38557-e071-4253-9886-7cb573d20dcb" class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Top 1 accuracy  : </span><span class="sc">{</span>top1<span class="sc">:.3f}</span><span class="ss">'</span>)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Top 2 accuracy  : </span><span class="sc">{</span>top2<span class="sc">:.3f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/github\.com\/yulinhuang\/WP10_tutorial_text_classification");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../data_preprocessing/data_augmentation.html" class="pagination-link" aria-label="Data augmentation">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Data augmentation</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../5_RAG/rag_classification.html" class="pagination-link" aria-label="RAG Classification">
        <span class="nav-page-text">RAG Classification</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.dev/yulinhuang/WP10_tutorial_text_classification/blob/main/model_training/fine-tuning-bert-example.ipynb" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/yulinhuang/WP10_tutorial_text_classification/blob/main/model_training/fine-tuning-bert-example.ipynb" class="toc-action"><i class="bi empty"></i>View source</a></li><li><a href="https://github.com/yulinhuang/WP10_tutorial_text_classification/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>